# Titanic Insights ğŸš¢

AnÃ¡lise completa e pipeline de Machine Learning para o clÃ¡ssico desafio do Kaggle: prever a sobrevivÃªncia de passageiros no desastre do Titanic. Este projeto implementa um fluxo de trabalho de ponta a ponta, desde o download dos dados atÃ© a implantaÃ§Ã£o de uma API de prediÃ§Ã£o.

![Interface da CLI](https://raw.githubusercontent.com/lucasgitdev/titanic-insights/main/reports/figures/cli_screenshot.png)

## âœ¨ Funcionalidades

- **CLI Interativa:** Uma interface de linha de comando moderna e amigÃ¡vel construÃ­da com `Click` e `Rich` para gerenciar todo o pipeline.
- **Pipeline de ML:** Etapas bem definidas para download, prÃ©-processamento, treinamento e avaliaÃ§Ã£o de modelos.
- **Engenharia de Features:** CriaÃ§Ã£o de novas features para melhorar a performance do modelo.
- **API de PrediÃ§Ã£o:** Uma API FastAPI com documentaÃ§Ã£o Swagger interativa para realizar prediÃ§Ãµes em tempo real.
- **Ambiente ReproduzÃ­vel:** Gerenciamento de dependÃªncias com `Poetry` para garantir a consistibilidade.
- **Jupyter Lab Integrado:** FÃ¡cil acesso ao ambiente de exploraÃ§Ã£o de dados.

## ğŸš€ ComeÃ§ando

Siga os passos abaixo para configurar e executar o projeto localmente.

### PrÃ©-requisitos

- Python 3.11 ou superior
- [Poetry](https://python-poetry.org/docs/#installation) para gerenciamento de dependÃªncias.

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**

   ```bash
   git clone https://github.com/lucasgitdev/titanic-insights.git
   cd titanic-insights
   ```
2. **Instale as dependÃªncias:**
   Use o Poetry para criar um ambiente virtual e instalar todos os pacotes necessÃ¡rios.

   ```bash
   poetry install
   ```
3. **Ative o ambiente virtual:**

   ```bash
   poetry shell
   ```

## ğŸ’» Uso

A principal forma de interagir com o projeto Ã© atravÃ©s da CLI.

### CLI Interativa

Para uma experiÃªncia guiada, execute o modo interativo:

```bash
titanic-insights
```

VocÃª verÃ¡ um menu com todas as opÃ§Ãµes disponÃ­veis:

```
ğŸ“‹ Menu Principal
â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ OpÃ§Ã£o â”ƒ DescriÃ§Ã£o                â”ƒ Status      â”ƒ
â”¡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ 1     â”‚ ğŸ“¥ Download dos dados    â”‚ âœ… DisponÃ­vel â”‚
â”‚ 2     â”‚ ğŸ” Explorar dados        â”‚ âœ… DisponÃ­vel â”‚
â”‚ 3     â”‚ ğŸ§¹ PrÃ©-processar dados   â”‚ âœ… DisponÃ­vel â”‚
â”‚ 4     â”‚ ğŸ¤– Treinar modelo        â”‚ âœ… DisponÃ­vel â”‚
â”‚ 5     â”‚ ğŸ“Š Avaliar modelo        â”‚ âœ… DisponÃ­vel â”‚
â”‚ 6     â”‚ ğŸ“ˆ Gerar insights        â”‚ ğŸ”„ Em desenvolvimento â”‚
â”‚ 7     â”‚ ğŸ“ Abrir Jupyter Lab     â”‚ âœ… DisponÃ­vel â”‚
â”‚ 8     â”‚ ğŸš€ Iniciar API           â”‚ âœ… DisponÃ­vel â”‚
â”‚ 0     â”‚ âŒ Sair                  â”‚ âœ… DisponÃ­vel â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comandos Diretos

VocÃª tambÃ©m pode executar cada etapa do pipeline como um comando direto:

- **Download dos dados do Kaggle:**

  ```bash
  titanic-insights download
  ```

  *(Requer configuraÃ§Ã£o do `kaggle.json`. Veja `KAGGLE_SETUP.md`)*
- **PrÃ©-processar os dados:**

  ```bash
  titanic-insights preprocess
  ```
- **Treinar o modelo:**

  ```bash
  titanic-insights train
  ```
- **Avaliar o modelo salvo:**

  ```bash
  titanic-insights evaluate
  ```
- **Iniciar a API de prediÃ§Ã£o:**

  ```bash
  titanic-insights api
  ```
- **Abrir o Jupyter Lab:**

  ```bash
  titanic-insights jupyter
  ```

## ğŸŒ API de PrediÃ§Ã£o

Para iniciar o servidor da API, execute o comando:

```bash
titanic-insights api
```

A API estarÃ¡ disponÃ­vel em `http://127.0.0.1:8000`.

A documentaÃ§Ã£o interativa do Swagger UI, onde vocÃª pode testar os endpoints diretamente do navegador, estÃ¡ em:
[**http://127.0.0.1:8000/docs**](http://127.0.0.1:8000/docs)

## ğŸ“ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                    # Dados brutos, processados e externos
â”œâ”€â”€ models/                  # Modelos treinados (.joblib)
â”œâ”€â”€ notebooks/               # Notebooks Jupyter para exploraÃ§Ã£o e experimentaÃ§Ã£o
â”œâ”€â”€ reports/                 # RelatÃ³rios e figuras geradas
â”œâ”€â”€ src/                     # CÃ³digo fonte do projeto
â”‚   â”œâ”€â”€ api/                 # MÃ³dulo da API FastAPI
â”‚   â”œâ”€â”€ data/                # Scripts para download e manipulaÃ§Ã£o de dados
â”‚   â”œâ”€â”€ model/               # Scripts para treinamento e avaliaÃ§Ã£o de modelos
â”‚   â””â”€â”€ processing/          # Scripts para prÃ©-processamento e engenharia de features
â”œâ”€â”€ tests/                   # Testes automatizados
â”œâ”€â”€ titanic_insights/        # MÃ³dulo da CLI
â””â”€â”€ poetry.toml              # Arquivo de configuraÃ§Ã£o do Poetry
```

## ğŸ› ï¸ Ferramentas Utilizadas

- **Linguagem:** Python 3.11
- **CLI:** Click, Rich
- **API:** FastAPI, Uvicorn
- **Machine Learning:** Scikit-learn, Pandas
- **DependÃªncias:** Poetry
- **Notebooks:** Jupyter Lab

---

Desenvolvido por Teles, Goulart e Ross.
